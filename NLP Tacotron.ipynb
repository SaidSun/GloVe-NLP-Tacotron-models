{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3d176-91ba-4428-a816-706cd7b5e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Embedding, LSTM, Bidirectional, Concatenate, Conv1D, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7958d6-2347-401f-92df-27826323d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationSensitiveAttention(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(LocationSensitiveAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_shape = list(input_shape)\n",
    "#         print(input_shape, list(input_shape[-1]))\n",
    "#         print(input_shape[-1][1])\n",
    "#         print(self.units, (input_shape[0][-1], self.units))\n",
    "        self.W1 = self.add_weight(name='W1',\n",
    "                                  shape=(input_shape[0][-1], self.units),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.W2 = self.add_weight(name='W2',\n",
    "                                  shape=(input_shape[-1][1], self.units),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.V = self.add_weight(name='V',\n",
    "                                  shape=(self.units, 1),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        super(LocationSensitiveAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        hidden_states, encoder_outputs = inputs  # encoder_outputs - выход энкодера\n",
    "        print(hidden_states.shape, self.W1.shape, tf.transpose(encoder_outputs, perm=[0, 2, 1]).shape)\n",
    "        \n",
    "        # Вычисление весов внимания\n",
    "        attention_weights = tf.matmul(hidden_states, self.W1)\n",
    "        attention_weights = tf.tanh(attention_weights)\n",
    "        \n",
    "        # Вектор контекста для каждой временной ступени\n",
    "        context_vectors = tf.matmul(attention_weights, tf.transpose(encoder_outputs, perm=[0, 2, 1]))\n",
    "\n",
    "        # Преобразование контекста\n",
    "        context_vectors = tf.matmul(context_vectors, self.W2)\n",
    "\n",
    "        return context_vectors\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(LocationSensitiveAttention, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a580397-c646-4387-b388-77a745024603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBHG(Layer):\n",
    "    \"\"\"Convolutional-Bank Highway Network (CBHG) layer.\"\"\"\n",
    "\n",
    "    def __init__(self, K=16, projection_dim=128, **kwargs):\n",
    "        super(CBHG, self).__init__(**kwargs)\n",
    "        self.K = K\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv_banks = []\n",
    "        for k in range(1, self.K + 1):\n",
    "            self.conv_banks.append(\n",
    "                Conv1D(filters=128, kernel_size=k, activation='relu', padding='same')\n",
    "            )\n",
    "        self.max_pool = MaxPooling2D(pool_size=(1, 2), padding='same')\n",
    "        self.conv_projection = Conv1D(filters=self.projection_dim, kernel_size=3, activation='relu', padding='same')\n",
    "        self.highway_layers = []\n",
    "        for _ in range(4):\n",
    "            self.highway_layers.append(\n",
    "                Highway(self.projection_dim)\n",
    "            )\n",
    "        super(CBHG, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        outputs = inputs\n",
    "        conv_bank_outputs = []\n",
    "        for conv_bank in self.conv_banks:\n",
    "            conv_bank_outputs.append(conv_bank(outputs))\n",
    "        conv_bank_outputs = tf.concat(conv_bank_outputs, axis=-1)\n",
    "        conv_bank_outputs = tf.expand_dims(conv_bank_outputs, axis=-1)\n",
    "        conv_bank_outputs = self.max_pool(conv_bank_outputs)\n",
    "        conv_bank_outputs = tf.squeeze(conv_bank_outputs, axis=-1)\n",
    "        conv_bank_outputs = self.conv_projection(conv_bank_outputs)\n",
    "        highway_outputs = conv_bank_outputs\n",
    "        for highway_layer in self.highway_layers:\n",
    "            highway_outputs = highway_layer(highway_outputs)\n",
    "        return highway_outputs\n",
    "\n",
    "class Highway(Layer):\n",
    "    \"\"\"Highway Network layer.\"\"\"\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Highway, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W_H = self.add_weight(name='W_H',\n",
    "                                  shape=(input_shape[-1], self.units),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.W_T = self.add_weight(name='W_T',\n",
    "                                  shape=(input_shape[-1], self.units),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.b_H = self.add_weight(name='b_H',\n",
    "                                  shape=(self.units,),\n",
    "                                  initializer='zeros',\n",
    "                                  trainable=True)\n",
    "        self.b_T = self.add_weight(name='b_T',\n",
    "                                  shape=(self.units,),\n",
    "                                  initializer='zeros',\n",
    "                                  trainable=True)\n",
    "        super(Highway, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        H = tf.nn.relu(tf.matmul(inputs, self.W_H) + self.b_H)\n",
    "        T = tf.sigmoid(tf.matmul(inputs, self.W_T) + self.b_T)\n",
    "        return T * H + (1 - T) * inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Highway, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n",
    "\n",
    "class Prenet(Layer):\n",
    "    \"\"\"Pre-net layer.\"\"\"\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Prenet, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense1 = Dense(units=self.units // 2, activation='relu')\n",
    "        self.dense2 = Dense(units=self.units, activation='relu')\n",
    "        super(Prenet, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Prenet, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n",
    "\n",
    "class Postnet(Layer):\n",
    "    \"\"\"Post-net layer.\"\"\"\n",
    "\n",
    "    def __init__(self, num_channels, **kwargs):\n",
    "        super(Postnet, self).__init__(**kwargs)\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = Conv1D(filters=self.num_channels, kernel_size=5, activation='relu', padding='same')\n",
    "        self.conv2 = Conv1D(filters=self.num_channels, kernel_size=5, activation='relu', padding='same')\n",
    "        self.conv3 = Conv1D(filters=self.num_channels, kernel_size=5, activation='relu', padding='same')\n",
    "        self.conv4 = Conv1D(filters=self.num_channels, kernel_size=5, activation='relu', padding='same')\n",
    "        self.conv5 = Conv1D(filters=self.num_channels, kernel_size=5, activation='relu', padding='same')\n",
    "        self.linear_projection = Conv1D(filters=80, kernel_size=1, activation='linear', padding='same')\n",
    "        super(Postnet, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.conv3(outputs)\n",
    "        outputs = self.conv4(outputs)\n",
    "        outputs = self.conv5(outputs)\n",
    "        outputs = self.linear_projection(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Postnet, self).get_config()\n",
    "        config.update({'num_channels': self.num_channels})\n",
    "        return config\n",
    "\n",
    "\n",
    "class Tacotron2(Model):\n",
    "    \"\"\"Tacotron 2 model.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_lstm_units, decoder_lstm_units, cbhg_units, postnet_channels, **kwargs):\n",
    "        super(Tacotron2, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_lstm_units = encoder_lstm_units\n",
    "        self.decoder_lstm_units = decoder_lstm_units\n",
    "        self.cbhg_units = cbhg_units\n",
    "        self.postnet_channels = postnet_channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Встраивание (Embedding) для преобразования слов в векторы\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim)\n",
    "\n",
    "        # Энкодер\n",
    "        self.encoder_lstm = Bidirectional(LSTM(units=self.encoder_lstm_units, return_sequences=True))\n",
    "        self.cbhg = CBHG(projection_dim=self.cbhg_units)\n",
    "\n",
    "        # Декодер\n",
    "        self.prenet = Prenet(units=256)\n",
    "        self.decoder_lstm = LSTM(units=self.decoder_lstm_units, return_sequences=True, return_state=True)\n",
    "        self.attention = LocationSensitiveAttention(units=self.decoder_lstm_units*2)\n",
    "\n",
    "        # Проектирование на мел-спектрограмму\n",
    "        self.linear_projection = Dense(units=80, activation='linear')\n",
    "\n",
    "        # Пост-нет\n",
    "        self.postnet = Postnet(num_channels=self.postnet_channels)\n",
    "\n",
    "        super(Tacotron2, self).build(input_shape)\n",
    "    @tf.function\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Встраивание текста\n",
    "        embedded_inputs = self.embedding(inputs)\n",
    "\n",
    "        # Энкодер\n",
    "        encoder_outputs = self.encoder_lstm(embedded_inputs)\n",
    "        encoder_outputs = self.cbhg(encoder_outputs)\n",
    "\n",
    "        # Декодер\n",
    "        decoder_inputs = tf.zeros((tf.shape(inputs)[0], 1, self.decoder_lstm_units))\n",
    "        decoder_hidden_state = tf.zeros((tf.shape(inputs)[0], self.decoder_lstm_units))\n",
    "        decoder_cell_state = tf.zeros((tf.shape(inputs)[0], self.decoder_lstm_units))\n",
    "        attention_weights = []\n",
    "        mel_outputs_array = tf.TensorArray(dtype=tf.float32, size=tf.shape(inputs)[1], dynamic_size=False)\n",
    "        for i in tf.range(tf.shape(inputs)[1]):\n",
    "            # Пренет\n",
    "            prenet_outputs = self.prenet(decoder_inputs)\n",
    "\n",
    "            # Декодер LSTM\n",
    "            decoder_outputs, decoder_hidden_state, decoder_cell_state = self.decoder_lstm(prenet_outputs, initial_state=[decoder_hidden_state, decoder_cell_state])\n",
    "\n",
    "            # Внимание\n",
    "            context_vector = self.attention([decoder_outputs, encoder_outputs])\n",
    "\n",
    "            # Соединение контекста и скрытых состояний декодера\n",
    "            concat_outputs = Concatenate()([context_vector, decoder_outputs])\n",
    "\n",
    "            # Линейное проектирование на мел-спектрограмму\n",
    "            mel_output = self.linear_projection(concat_outputs)\n",
    "    \n",
    "\n",
    "            # Сохранение весов внимания\n",
    "            attention_weights.append(tf.reduce_sum(context_vector * encoder_outputs, axis=-1))\n",
    "            mel_outputs_array = mel_outputs_array.write(i, mel_output)\n",
    "\n",
    "            # Обновление входных данных декодера\n",
    "            decoder_inputs = decoder_outputs\n",
    "            \n",
    "\n",
    "        # Создание тензора мел-спектрограмм\n",
    "    \n",
    "        mel_outputs =  mel_outputs_array.concat()\n",
    "        # Пост-нет\n",
    "        postnet_outputs = self.postnet(mel_outputs)\n",
    "        print(mel_outputs)\n",
    "\n",
    "        # Добавление мел-спектрограмм и выходных данных пост-нета\n",
    "        outputs = Concatenate()([mel_outputs, postnet_outputs])\n",
    "\n",
    "        return outputs, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a75755-d51e-4c4c-8fc6-c13545978e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
