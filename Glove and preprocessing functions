{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d24a0-67c8-4226-b54c-8c16bb5a2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6c225-d5b2-4d83-8d58-75d43910e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list(filepath):\n",
    "    try:\n",
    "      with open(filepath, 'r', encoding='utf-8') as file: #encoding='utf-8' для корректной обработки разных символов\n",
    "        lines = file.readlines() #читает все строки в список\n",
    "        # Удаление символов новой строки и пробельных символов в начале и конце каждой строки\n",
    "        lines = [line.strip() for line in lines]\n",
    "      return lines\n",
    "    except FileNotFoundError:\n",
    "      return f\"Файл по пути '{filepath}' не найден.\"\n",
    "    except Exception as e:\n",
    "        return f\"Ошибка при чтении файла: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848b9c0-bc31-41bd-a5d0-16cff473b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала реализуем модель GloVe для создания эмбеддинга слов\n",
    "class GloVe:\n",
    "    def __init__(self, context: int, length:int):\n",
    "        self.v = list()\n",
    "        self.P = list()\n",
    "        self.context = context\n",
    "        self.words = set()\n",
    "        self.length = length\n",
    "        self.sums = []\n",
    "        \n",
    "    def making_corr_matrix(self, texts: list()):\n",
    "        symbols = \"_-!'(),.:;?\"\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            new_text = text.lower()\n",
    "            for elem in symbols:\n",
    "                new_text = new_text.replace(elem, f' {elem}')\n",
    "            new_text = re.split(r'\\s+', new_text)\n",
    "            sequences.append(new_text)\n",
    "            new_text = set(new_text)\n",
    "            self.words.update(new_text)\n",
    "        self.words = self.words ^ set('')\n",
    "        #2 - Создать пустой массив корреляций слов и заполнять его\n",
    "        vocab_size = len(self.words)\n",
    "        self.words = list(self.words)\n",
    "        self.P = np.zeros((vocab_size, vocab_size), dtype=np.float32)\n",
    "        self.sums = np.zeros(vocab_size, dtype=np.float32)\n",
    "        for sequence in sequences:\n",
    "            indices = [self.words.index(word) for word in sequence]\n",
    "            for i, elem_index in enumerate(indices):\n",
    "               for j in range(max(0, i - self.context), min(len(indices), i + self.context+1)):\n",
    "                    if i != j:\n",
    "                        context_index = indices[j]\n",
    "                        self.P[elem_index, context_index] += 1\n",
    "        # Нормализация матрицы и подсчет сумм\n",
    "        self.sums = np.sum(self.P, axis=1) #  более эффективно, чем циклы\n",
    "        self.P = self.P / (self.sums[:, None] + 1e-8)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def fit(self, texts: list(), epochs:int, a:float, h = 0.01, eps = 1e-8):\n",
    "        print(\"Разделение текста на слова...\")\n",
    "        self.making_corr_matrix(texts)\n",
    "        print(\"Предбработка завершена!\")\n",
    "        self.v = [np.random.normal(0, 1, self.length) for i in range(len(self.words))]\n",
    "        row_indices = list(range(len(self.v)))\n",
    "        G_i = np.zeros(len(self.words))\n",
    "        G_j = np.zeros(len(self.words))\n",
    "        print(\"Начало обучения...\")\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(self.words)):\n",
    "                for j in range(len(self.words)):\n",
    "                    # random_indices = random.sample(row_indices, 2)\n",
    "                    v_i, v_j = self.v[i], self.v[j]\n",
    "                    aim = np.log(self.P[i, j] + 1)\n",
    "                    prediction = np.dot(v_i, v_j)\n",
    "                    w_ij = min(1, (self.P[i, j]/(self.sums[i]+1))**a)\n",
    "                    error = w_ij*(aim - prediction)**2\n",
    "                    dv_i = 2*w_ij*v_j\n",
    "                    dv_j = 2*w_ij*v_i\n",
    "                    G_i[i] += np.dot(dv_i, dv_i)\n",
    "                    G_j[j] += np.dot(dv_j, dv_j)\n",
    "                    v_i += (-h*dv_i/((G_i[i] + eps)))\n",
    "                    v_j += (-h*dv_j/((G_j[j] + eps)))\n",
    "            print(f\"Epoch: {epoch}, v_i: {v_i}, v_j: {v_j}, error: {error}\")\n",
    "        \n",
    "        self.fitted = dict()\n",
    "        for index, word in enumerate(self.words):\n",
    "            self.fitted[word] = self.v[index]\n",
    "        return self.fitted\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        symbols = \"_-!'(),.:;?\"\n",
    "        sequences = []\n",
    "         #создание паттерна для re.sub\n",
    "        symbols_pattern = re.compile(r'([' + re.escape(symbols) + r'])')\n",
    "        for text in texts:\n",
    "            new_text = text.lower()\n",
    "            for elem in symbols:\n",
    "                new_text = new_text.replace(elem, f' {elem}')\n",
    "            new_text = re.split(r'\\s+', new_text)\n",
    "            self.words = set(new_text)\n",
    "            self.words = self.words ^ set('')\n",
    "            for index, word in enumerate(new_text):\n",
    "                new_text[index] = list(self.fitted[word])\n",
    "            sequences.append(np.array(new_text).flatten())\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003c40d-cf95-4320-a825-92679677c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_mel():\n",
    "    audio_length_seconds = 2\n",
    "    mels = dict()\n",
    "    srs = 32000\n",
    "    hop_length = int((audio_length_seconds * srs) / 54)\n",
    "    desired_frames = 54\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            if '.wav' in filename:\n",
    "                y, sr = librosa.load(os.path.join(dirname, filename), sr=32000, mono=True)\n",
    "                mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=hop_length)\n",
    "                desired_frames = 100\n",
    "                if mel_spec.shape[1] < desired_frames:\n",
    "                    padding = np.zeros((mel_spec.shape[0], desired_frames - mel_spec.shape[1]))\n",
    "                    mel_spec = np.concatenate((mel_spec, padding), axis=1)\n",
    "                mels[filename] = mel_spec\n",
    "    return mels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
